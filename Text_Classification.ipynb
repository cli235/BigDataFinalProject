{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGqGzfmfY99g",
        "outputId": "8c6c521f-c9af-4a13-fa41-615a799b36f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pyspark\n",
            "  Downloading pyspark-3.4.0.tar.gz (310.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.8/310.8 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.4.0-py2.py3-none-any.whl size=311317145 sha256=7282e4d3c5d92c1f35dcbdd07367a0ba93f6d2c4fd9a8fc1353caac28a7c3971\n",
            "  Stored in directory: /root/.cache/pip/wheels/7b/1b/4b/3363a1d04368e7ff0d408e57ff57966fcdf00583774e761327\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.4.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "# Build a spark context\n",
        "hc = (SparkSession.builder\n",
        "                  .appName('Toxic Comment Classification')\n",
        "                  .enableHiveSupport()\n",
        "                  .config(\"spark.executor.memory\", \"4G\")\n",
        "                  .config(\"spark.driver.memory\",\"18G\")\n",
        "                  .config(\"spark.executor.cores\",\"7\")\n",
        "                  .config(\"spark.python.worker.memory\",\"4G\")\n",
        "                  .config(\"spark.driver.maxResultSize\",\"0\")\n",
        "                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n",
        "                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n",
        "                  .config(\"spark.default.parallelism\",\"2\")\n",
        "                  .getOrCreate())\n",
        "\n",
        "hc.sparkContext.setLogLevel('INFO')\n",
        "hc.version"
      ],
      "metadata": {
        "id": "ryTXGCKTa8wj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "da3b46b5-1a25-4a84-b318-9276914e8746"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'3.4.0'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "import pyspark.sql.types as T\n",
        "from pyspark.ml.feature import Tokenizer, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "\n",
        "hc = (SparkSession.builder\n",
        "                  .appName('Toxic Comment Classification')\n",
        "                  .enableHiveSupport()\n",
        "                  .config(\"spark.executor.memory\", \"4G\")\n",
        "                  .config(\"spark.driver.memory\",\"18G\")\n",
        "                  .config(\"spark.executor.cores\",\"7\")\n",
        "                  .config(\"spark.python.worker.memory\",\"4G\")\n",
        "                  .config(\"spark.driver.maxResultSize\",\"0\")\n",
        "                  .config(\"spark.sql.crossJoin.enabled\", \"true\")\n",
        "                  .config(\"spark.serializer\",\"org.apache.spark.serializer.KryoSerializer\")\n",
        "                  .config(\"spark.default.parallelism\",\"2\")\n",
        "                  .getOrCreate())\n",
        "\n",
        "def to_spark_df(fin):\n",
        "    try:\n",
        "        df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Skipping problematic rows in file {fin}...\")\n",
        "        df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
        "\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.astype(str)\n",
        "    sdf = hc.createDataFrame(df)\n",
        "    sdf = sdf.select([F.col(col).alias(col.strip().replace(\" \", \"_\")) for col in sdf.columns])\n",
        "    return sdf\n",
        "\n",
        "# Load the train-test sets\n",
        "train = to_spark_df(\"/content/train.csv\")\n",
        "test = to_spark_df(\"/content/test.csv\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OTyGTrBqk55e",
        "outputId": "0b2f9d9d-a105-4c22-f99f-278685c3f376"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-9305b5f92fe9>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False)\n",
            "<ipython-input-2-9305b5f92fe9>:24: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def to_spark_df(fin):\n",
        "    try:\n",
        "        df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False)\n",
        "    except pd.errors.ParserError as e:\n",
        "        print(f\"Skipping problematic rows in file {fin}...\")\n",
        "        df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False, quoting=csv.QUOTE_NONE)\n",
        "\n",
        "    df = df.dropna()\n",
        "    df = df.drop_duplicates()\n",
        "    df = df.astype(str)\n",
        "    sdf = hc.createDataFrame(df)\n",
        "    sdf = sdf.select([F.col(col).alias(col.strip().replace(\" \", \"_\")) for col in sdf.columns])\n",
        "    return sdf\n",
        "\n",
        "# Load the train-test sets\n",
        "train = to_spark_df(\"/content/train.csv\")\n",
        "test = to_spark_df(\"/content/test.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XM6mCImpHNiZ",
        "outputId": "1fed6e98-5a7b-48a8-aad5-5704cceb2aae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-e84907e942ba>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False)\n",
            "<ipython-input-3-e84907e942ba>:3: FutureWarning: The error_bad_lines argument has been deprecated and will be removed in a future version. Use on_bad_lines in the future.\n",
            "\n",
            "\n",
            "  df = pd.read_csv(fin, encoding='latin1', error_bad_lines=False)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.show(5)\n",
        "test.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGc-EljzlecH",
        "outputId": "23c95708-2b1c-447e-a068-a192b170be59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "|0000997932d777bf|Explanation\\nWhy ...|    0|           0|      0|     0|     0|            0|\n",
            "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|\n",
            "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|\n",
            "|0001b41b1c6bb37e|\"\\nMore\\nI can't ...|    0|           0|      0|     0|     0|            0|\n",
            "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------------+--------------------+\n",
            "|              id|        comment_text|\n",
            "+----------------+--------------------+\n",
            "|00001cee341fdb12|Yo bitch Ja Rule ...|\n",
            "|0000247867823ef7|== From RfC == \\n...|\n",
            "|00013b17ad220c46|\" \\n\\n == Sources...|\n",
            "|00017563c3f7919a|:If you have a lo...|\n",
            "|00017695ad8997eb|I don't anonymous...|\n",
            "+----------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_cols = [i for i in train.columns if i not in [\"id\", \"comment_text\"]]\n",
        "train.show(5)\n",
        "# View some toxic comments\n",
        "train.filter(F.col('toxic') == 1).show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AHvXzx3Kl-A5",
        "outputId": "0ee7839b-d6ef-4a6b-d2f4-dafab68c3685"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "|0000997932d777bf|Explanation\\nWhy ...|    0|           0|      0|     0|     0|            0|\n",
            "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|\n",
            "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|\n",
            "|0001b41b1c6bb37e|\"\\nMore\\nI can't ...|    0|           0|      0|     0|     0|            0|\n",
            "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "|0002bcb3da6cb337|COCKSUCKER BEFORE...|    1|           1|      1|     0|     1|            0|\n",
            "|0005c987bdfc9d4b|Hey... what is it...|    1|           0|      0|     0|     0|            0|\n",
            "|0007e25b2121310b|Bye! \\n\\nDon't lo...|    1|           0|      0|     0|     0|            0|\n",
            "|001810bf8c45bf5f|You are gay or an...|    1|           0|      1|     0|     1|            1|\n",
            "|00190820581d90ce|FUCK YOUR FILTHY ...|    1|           0|      1|     0|     1|            0|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Basic sentence tokenizer\n",
        "tokenizer = Tokenizer(inputCol=\"comment_text\", outputCol=\"words\")\n",
        "wordsData = tokenizer.transform(train)\n",
        "# Count the words in a document\n",
        "hashingTF = HashingTF(inputCol=\"words\", outputCol=\"rawFeatures\")\n",
        "tf = hashingTF.transform(wordsData)\n",
        "tf.select('rawFeatures').take(2)\n"
      ],
      "metadata": {
        "id": "eOvft-4WmVev",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc2f59e2-4b79-494c-c789-140851dedfe1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Row(rawFeatures=SparseVector(262144, {6240: 1.0, 7221: 1.0, 9420: 1.0, 10214: 1.0, 11680: 1.0, 15494: 1.0, 19036: 1.0, 19208: 1.0, 23032: 1.0, 25000: 1.0, 26144: 1.0, 66299: 1.0, 67416: 1.0, 72125: 1.0, 74944: 1.0, 77971: 1.0, 79300: 1.0, 79968: 1.0, 89833: 1.0, 94488: 1.0, 95889: 3.0, 97171: 1.0, 101169: 1.0, 103863: 1.0, 110427: 1.0, 110510: 1.0, 116767: 1.0, 140784: 1.0, 141086: 1.0, 145284: 1.0, 151536: 1.0, 151751: 1.0, 166368: 1.0, 187114: 1.0, 219915: 1.0, 223402: 1.0, 229137: 1.0, 231630: 1.0, 233967: 1.0, 240944: 1.0, 253170: 1.0})),\n",
              " Row(rawFeatures=SparseVector(262144, {2195: 1.0, 4714: 1.0, 13283: 1.0, 48234: 1.0, 85939: 1.0, 108541: 1.0, 119702: 1.0, 121320: 1.0, 137179: 1.0, 141086: 1.0, 159767: 1.0, 165258: 1.0, 169800: 1.0, 212492: 1.0, 218233: 1.0, 224255: 1.0, 224850: 1.0, 249180: 1.0}))]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the idf model and transform the original token frequencies into their tf-idf counterparts\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "idfModel = idf.fit(tf) \n",
        "tfidf = idfModel.transform(tf)\n",
        "tfidf.select(\"features\").first()"
      ],
      "metadata": {
        "id": "b7VsQCEomhIY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f03dd8bb-d28d-4fa7-af87-01a4c62da7d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(features=SparseVector(262144, {6240: 8.7614, 7221: 2.2031, 9420: 3.1544, 10214: 6.4668, 11680: 5.0285, 15494: 3.4225, 19036: 0.7388, 19208: 2.2452, 23032: 5.0123, 25000: 5.6905, 26144: 3.5882, 66299: 7.7906, 67416: 1.1955, 72125: 2.2737, 74944: 2.5143, 77971: 7.6235, 79300: 6.6769, 79968: 9.9008, 89833: 3.0525, 94488: 8.4249, 95889: 1.2134, 97171: 2.0171, 101169: 1.735, 103863: 6.8444, 110427: 2.1179, 110510: 5.6685, 116767: 6.0244, 140784: 3.0501, 141086: 2.4784, 145284: 8.0884, 151536: 2.2433, 151751: 9.0358, 166368: 2.0436, 187114: 1.7668, 219915: 0.697, 223402: 3.3526, 229137: 4.5711, 231630: 9.4953, 233967: 3.103, 240944: 1.7546, 253170: 2.7016}))"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REG = 0.1\n",
        "lr = LogisticRegression(featuresCol=\"features\", labelCol='toxic', regParam=REG)\n",
        "tfidf.show(5)"
      ],
      "metadata": {
        "id": "-JmJuzDFmyqU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ac3d796-2d85-4d8a-fa80-58f25a7f3b28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n",
            "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|               words|         rawFeatures|            features|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n",
            "|0000997932d777bf|Explanation\\nWhy ...|    0|           0|      0|     0|     0|            0|[explanation, why...|(262144,[6240,722...|(262144,[6240,722...|\n",
            "|000103f0d9cfb60f|D'aww! He matches...|    0|           0|      0|     0|     0|            0|[d'aww!, he, matc...|(262144,[2195,471...|(262144,[2195,471...|\n",
            "|000113f07ec002fd|Hey man, I'm real...|    0|           0|      0|     0|     0|            0|[hey, man,, i'm, ...|(262144,[18700,27...|(262144,[18700,27...|\n",
            "|0001b41b1c6bb37e|\"\\nMore\\nI can't ...|    0|           0|      0|     0|     0|            0|[\", more, i, can'...|(262144,[11104,16...|(262144,[11104,16...|\n",
            "|0001d958c54c6e35|You, sir, are my ...|    0|           0|      0|     0|     0|            0|[you,, sir,, are,...|(262144,[20853,58...|(262144,[20853,58...|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "tfidf = tfidf.withColumn(\"toxic\", col(\"toxic\").cast(\"double\"))\n",
        "lrModel = lr.fit(tfidf.limit(4000))\n",
        "res_train = lrModel.transform(tfidf)\n",
        "res_train.select(\"id\", \"toxic\", \"probability\", \"prediction\").show(10)\n",
        "res_train.show(5)"
      ],
      "metadata": {
        "id": "BZRGohrF2Uj0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a925e534-7a49-4dbc-a481-8bbf4888da61"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+-----+--------------------+----------+\n",
            "|              id|toxic|         probability|prediction|\n",
            "+----------------+-----+--------------------+----------+\n",
            "|0000997932d777bf|  0.0|[0.98708414415883...|       0.0|\n",
            "|000103f0d9cfb60f|  0.0|[0.98578386377281...|       0.0|\n",
            "|000113f07ec002fd|  0.0|[0.95195125534514...|       0.0|\n",
            "|0001b41b1c6bb37e|  0.0|[0.99406923917414...|       0.0|\n",
            "|0001d958c54c6e35|  0.0|[0.96920502028432...|       0.0|\n",
            "|00025465d4725e87|  0.0|[0.96326972334709...|       0.0|\n",
            "|0002bcb3da6cb337|  1.0|[0.28384026420489...|       1.0|\n",
            "|00031b1e95af7921|  0.0|[0.96521315191035...|       0.0|\n",
            "|00037261f536c51d|  0.0|[0.98623994566883...|       0.0|\n",
            "|00040093b2687caa|  0.0|[0.97061660492107...|       0.0|\n",
            "+----------------+-----+--------------------+----------+\n",
            "only showing top 10 rows\n",
            "\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|              id|        comment_text|toxic|severe_toxic|obscene|threat|insult|identity_hate|               words|         rawFeatures|            features|       rawPrediction|         probability|prediction|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "|0000997932d777bf|Explanation\\nWhy ...|  0.0|           0|      0|     0|     0|            0|[explanation, why...|(262144,[6240,722...|(262144,[6240,722...|[4.33629959666674...|[0.98708414415883...|       0.0|\n",
            "|000103f0d9cfb60f|D'aww! He matches...|  0.0|           0|      0|     0|     0|            0|[d'aww!, he, matc...|(262144,[2195,471...|(262144,[2195,471...|[4.23905945200265...|[0.98578386377281...|       0.0|\n",
            "|000113f07ec002fd|Hey man, I'm real...|  0.0|           0|      0|     0|     0|            0|[hey, man,, i'm, ...|(262144,[18700,27...|(262144,[18700,27...|[2.98629782184644...|[0.95195125534514...|       0.0|\n",
            "|0001b41b1c6bb37e|\"\\nMore\\nI can't ...|  0.0|           0|      0|     0|     0|            0|[\", more, i, can'...|(262144,[11104,16...|(262144,[11104,16...|[5.12165435541236...|[0.99406923917414...|       0.0|\n",
            "|0001d958c54c6e35|You, sir, are my ...|  0.0|           0|      0|     0|     0|            0|[you,, sir,, are,...|(262144,[20853,58...|(262144,[20853,58...|[3.44912448830203...|[0.96920502028432...|       0.0|\n",
            "+----------------+--------------------+-----+------------+-------+------+------+-------------+--------------------+--------------------+--------------------+--------------------+--------------------+----------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extract_prob = F.udf(lambda x: float(x[1]), T.FloatType())\n",
        "(res_train.withColumn(\"proba\", extract_prob(\"probability\"))\n",
        " .select(\"proba\", \"prediction\").show())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wiatlNWs4Hu0",
        "outputId": "ef18d6ce-f711-4a58-807a-ad02f131b19f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+----------+\n",
            "|       proba|prediction|\n",
            "+------------+----------+\n",
            "| 0.012915856|       0.0|\n",
            "| 0.014216136|       0.0|\n",
            "| 0.048048746|       0.0|\n",
            "| 0.005930761|       0.0|\n",
            "|  0.03079498|       0.0|\n",
            "|  0.03673028|       0.0|\n",
            "|  0.71615976|       1.0|\n",
            "| 0.034786846|       0.0|\n",
            "|0.0137600545|       0.0|\n",
            "| 0.029383395|       0.0|\n",
            "| 8.825276E-6|       0.0|\n",
            "| 0.028142199|       0.0|\n",
            "|   0.9568293|       1.0|\n",
            "|0.0036047543|       0.0|\n",
            "| 0.017964894|       0.0|\n",
            "| 0.005057816|       0.0|\n",
            "|   0.8439702|       1.0|\n",
            "| 0.023082986|       0.0|\n",
            "| 0.019967748|       0.0|\n",
            "| 0.012109306|       0.0|\n",
            "+------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_tokens = tokenizer.transform(test)\n",
        "test_tf = hashingTF.transform(test_tokens)\n",
        "test_tfidf = idfModel.transform(test_tf)\n",
        "\n",
        "test_res = test.select('id')\n",
        "test_res.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8a6G2ak4X4j",
        "outputId": "4b717090-9587-4748-86cf-15a90cb32794"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Row(id='00001cee341fdb12')"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "tfidf = tfidf.withColumn(\"severe_toxic\", col(\"severe_toxic\").cast(\"double\"))\n",
        "tfidf = tfidf.withColumn(\"obscene\", col(\"obscene\").cast(\"double\"))\n",
        "tfidf = tfidf.withColumn(\"threat\", col(\"threat\").cast(\"double\"))\n",
        "tfidf = tfidf.withColumn(\"insult\", col(\"insult\").cast(\"double\"))\n",
        "tfidf = tfidf.withColumn(\"identity_hate\", col(\"identity_hate\").cast(\"double\"))"
      ],
      "metadata": {
        "id": "eaniV2pT6W8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "test_probs = []\n",
        "for col in out_cols:\n",
        "    print(col)\n",
        "    lr = LogisticRegression(featuresCol=\"features\", labelCol=col, regParam=REG)\n",
        "    print(\"...fitting\")\n",
        "    lrModel = lr.fit(tfidf)\n",
        "    print(\"...predicting\")\n",
        "    res = lrModel.transform(test_tfidf)\n",
        "    print(\"...appending result\")\n",
        "    test_res = test_res.join(res.select('id', 'probability'), on=\"id\")\n",
        "    print(\"...extracting probability\")\n",
        "    test_res = test_res.withColumn(col, extract_prob('probability')).drop(\"probability\")\n",
        "    test_res.show(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DKzdIsKg4gIq",
        "outputId": "539f9632-156b-48fd-b051-c2cea0341ae2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "toxic\n",
            "...fitting\n",
            "...predicting\n",
            "...appending result\n",
            "...extracting probability\n",
            "+----------------+-----------+\n",
            "|              id|      toxic|\n",
            "+----------------+-----------+\n",
            "|000968ce11f5ee34|0.047582276|\n",
            "|00491682330fdd1d|3.734712E-9|\n",
            "|008eb47c4684d190|  0.9069167|\n",
            "|00d251f47486b6d2| 0.06388117|\n",
            "|0114ae82c53101a9|  0.5112876|\n",
            "+----------------+-----------+\n",
            "only showing top 5 rows\n",
            "\n",
            "severe_toxic\n",
            "...fitting\n",
            "...predicting\n",
            "...appending result\n",
            "...extracting probability\n",
            "+----------------+-----------+------------+\n",
            "|              id|      toxic|severe_toxic|\n",
            "+----------------+-----------+------------+\n",
            "|000968ce11f5ee34|0.047582276|0.0077139614|\n",
            "|00491682330fdd1d|3.734712E-9|2.5387094E-6|\n",
            "|008eb47c4684d190|  0.9069167|0.0013850711|\n",
            "|00d251f47486b6d2| 0.06388117| 0.007744039|\n",
            "|0114ae82c53101a9|  0.5112876|  0.07452955|\n",
            "+----------------+-----------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "obscene\n",
            "...fitting\n",
            "...predicting\n",
            "...appending result\n",
            "...extracting probability\n",
            "+----------------+-----------+------------+-------------+\n",
            "|              id|      toxic|severe_toxic|      obscene|\n",
            "+----------------+-----------+------------+-------------+\n",
            "|000968ce11f5ee34|0.047582276|0.0077139614|  0.039543014|\n",
            "|00491682330fdd1d|3.734712E-9|2.5387094E-6|4.3590598E-10|\n",
            "|008eb47c4684d190|  0.9069167|0.0013850711| 0.0069578085|\n",
            "|00d251f47486b6d2| 0.06388117| 0.007744039|   0.03563852|\n",
            "|0114ae82c53101a9|  0.5112876|  0.07452955|     0.312121|\n",
            "+----------------+-----------+------------+-------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "threat\n",
            "...fitting\n",
            "...predicting\n",
            "...appending result\n",
            "...extracting probability\n",
            "+----------------+-----------+------------+-------------+------------+\n",
            "|              id|      toxic|severe_toxic|      obscene|      threat|\n",
            "+----------------+-----------+------------+-------------+------------+\n",
            "|000968ce11f5ee34|0.047582276|0.0077139614|  0.039543014|0.0024656388|\n",
            "|00491682330fdd1d|3.734712E-9|2.5387094E-6|4.3590598E-10|5.1305997E-5|\n",
            "|008eb47c4684d190|  0.9069167|0.0013850711| 0.0069578085|0.0011201394|\n",
            "|00d251f47486b6d2| 0.06388117| 0.007744039|   0.03563852|0.0022790588|\n",
            "|0114ae82c53101a9|  0.5112876|  0.07452955|     0.312121|0.0043284316|\n",
            "+----------------+-----------+------------+-------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "insult\n",
            "...fitting\n",
            "...predicting\n",
            "...appending result\n",
            "...extracting probability\n",
            "+----------------+-----------+------------+-------------+------------+------------+\n",
            "|              id|      toxic|severe_toxic|      obscene|      threat|      insult|\n",
            "+----------------+-----------+------------+-------------+------------+------------+\n",
            "|000968ce11f5ee34|0.047582276|0.0077139614|  0.039543014|0.0024656388| 0.031455696|\n",
            "|00491682330fdd1d|3.734712E-9|2.5387094E-6|4.3590598E-10|5.1305997E-5|1.4760833E-9|\n",
            "|008eb47c4684d190|  0.9069167|0.0013850711| 0.0069578085|0.0011201394|  0.03289113|\n",
            "|00d251f47486b6d2| 0.06388117| 0.007744039|   0.03563852|0.0022790588|  0.03734809|\n",
            "|0114ae82c53101a9|  0.5112876|  0.07452955|     0.312121|0.0043284316|  0.19731727|\n",
            "+----------------+-----------+------------+-------------+------------+------------+\n",
            "only showing top 5 rows\n",
            "\n",
            "identity_hate\n",
            "...fitting\n",
            "...predicting\n",
            "...appending result\n",
            "...extracting probability\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_res.coalesce(1).write.csv('/content/sample_data/spark_lr.csv', mode='overwrite', header=True)\n"
      ],
      "metadata": {
        "id": "e61LlcUEgKjs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /content/sample_data/spark_lr.csv/part*.csv > spark_lr.csv"
      ],
      "metadata": {
        "id": "peqXXulsjcrh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}